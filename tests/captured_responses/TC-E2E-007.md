## Summary
The recommended streaming design is Pub/Sub -> Dataflow -> BigQuery with dead-letter handling and per-user ordering keys.

## Decision
Use Pub/Sub topics with schema validation, Dataflow for transformations, and BigQuery sink via Storage Write API. Configure dead-letter topics and document ordering strategy by user_id.

## Rationale
This design provides scalable processing for 30K events/sec while preserving per-key ordering. Dead-letter routing improves resilience. The architecture can choose exactly-once where correctness is critical, or at-least-once with idempotent sinks for higher throughput.

## Trade-offs
| Option | Pros | Cons | When to Use |
|--------|------|------|-------------|
| Exactly-once | Strong correctness guarantees | Added latency and lower throughput | Financial/counting workloads |
| At-least-once | Higher throughput, simpler operations | Requires deduplication/idempotency | Non-critical high-volume streams |

## Next Steps
1. Create Pub/Sub topic/subscription plan with ordering keys.
2. Implement Dataflow pipeline and BigQuery sink strategy.
3. Configure dead-letter topic alerts and replay runbook.
4. Load-test throughput and monitor ordering lag.
